# ===========================================
# Infinity Assistant Service Environment
# ===========================================

# Supabase Configuration
# Get these from your Supabase project settings
NEXT_PUBLIC_SUPABASE_URL=https://your-project.supabase.co
UAA2_SUPABASE_SERVICE_KEY=your-service-role-key

# UAA2 Service Configuration
# URL to the uaa2-service backend (Railway deployment)
UAA2_SERVICE_URL=https://uaa2-service-production.up.railway.app
UAA2_SERVICE_API_KEY=optional-api-key-for-auth

# Clerk Authentication
NEXT_PUBLIC_CLERK_PUBLISHABLE_KEY=pk_live_xxx
CLERK_SECRET_KEY=sk_live_xxx

# Stripe Payments
NEXT_PUBLIC_STRIPE_PUBLISHABLE_KEY=pk_live_xxx
STRIPE_SECRET_KEY=sk_live_xxx

# Crypto Payments (Base Network)
# Treasury wallet address that receives $BRIAN and USDC payments
TREASURY_WALLET_ADDRESS=0x...your-treasury-wallet
# $BRIAN token contract address on Base
BRIAN_TOKEN_ADDRESS=0x...brian-token-contract
# Base RPC (optional, defaults to https://mainnet.base.org)
BASE_RPC_URL=https://mainnet.base.org

# ===========================================
# Mesh Network Configuration
# ===========================================

# Enable user mesh network (allows users to join the mesh)
MESH_ENABLED=true

# Mesh node self-identification
MESH_NODE_ID=infinity-assistant
MESH_NODE_NAME=InfinityAssistant (Vercel)

# Connected mesh nodes
UAA2_MESH_URL=https://uaa2-service-production.up.railway.app
OLLAMA_MESH_URL=http://localhost:11434
AI_WORKSPACE_PATH=c:/Users/your-user/Documents/GitHub/AI_Workspace

# User mesh settings
USER_MESH_DEFAULT_TIER=free
USER_MESH_MAX_CONNECTIONS=50

# ===========================================
# Cron Job Authentication
# ===========================================

# Secret for authenticating cron job requests
# Generate with: openssl rand -base64 32
CRON_SECRET=your-cron-secret-here

# QStash signing key (optional - for Upstash QStash support)
QSTASH_CURRENT_SIGNING_KEY=

# ===========================================
# LLM Configuration
# ===========================================

# Default LLM provider (claude, openai, nvidia, ollama, etc.)
DEFAULT_LLM_PROVIDER=claude

# LLM request timeout in milliseconds (default: 60000)
LLM_TIMEOUT=60000

# Master Portal URL (for knowledge base and agent APIs)
MASTER_PORTAL_URL=http://localhost:3000

# ===========================================
# Optional Configuration
# ===========================================
LOG_LEVEL=info
