/**
 * Content Generation API
 *
 * Generates content using AI capabilities:
 * - Documents (markdown, text, reports)
 * - Code files
 * - Data exports (JSON, CSV)
 *
 * For images and media, this endpoint can coordinate with
 * external generation services when configured.
 */

import { NextRequest, NextResponse } from 'next/server';
import { getUserContentStorageService } from '@/services/UserContentStorageService';
import { getUserService } from '@/services/UserService';
import { getUnifiedLLMClient } from '@/lib/llm/UnifiedLLMClient';
import logger from '@/utils/logger';

// ============================================================================
// TYPES
// ============================================================================

interface GenerationRequest {
  type: 'document' | 'code' | 'data' | 'report' | 'summary';
  prompt: string;
  conversationId?: string;
  options?: {
    format?: 'markdown' | 'text' | 'json' | 'csv' | 'html';
    style?: 'formal' | 'casual' | 'technical';
    length?: 'short' | 'medium' | 'long';
    title?: string;
  };
}

interface GenerationResult {
  success: boolean;
  content?: {
    id: string;
    name: string;
    type: string;
    url: string;
  };
  preview?: string;
  tokensUsed?: number;
  aiPowered?: boolean;
  error?: string;
}

// ============================================================================
// GENERATION TEMPLATES
// ============================================================================

const DOCUMENT_TEMPLATES = {
  report: {
    prefix: '# Report\n\nGenerated on: {{date}}\n\n## Summary\n\n',
    suffix: '\n\n---\n*Generated by Infinity Assistant*',
  },
  summary: {
    prefix: '# Summary\n\n',
    suffix: '\n\n---\n*Generated by Infinity Assistant*',
  },
  document: {
    prefix: '',
    suffix: '\n\n---\n*Created with Infinity Assistant*',
  },
};

// ============================================================================
// GENERATION FUNCTIONS
// ============================================================================

/**
 * Generate a document based on prompt using AI
 */
async function generateDocument(
  prompt: string,
  options: GenerationRequest['options']
): Promise<{ content: string; mimeType: string; extension: string; tokensUsed: number }> {
  const format = options?.format || 'markdown';
  const template = DOCUMENT_TEMPLATES[options?.style as keyof typeof DOCUMENT_TEMPLATES] || DOCUMENT_TEMPLATES.document;

  const mimeTypes: Record<string, string> = {
    markdown: 'text/markdown',
    text: 'text/plain',
    json: 'application/json',
    csv: 'text/csv',
    html: 'text/html',
  };

  const extensions: Record<string, string> = {
    markdown: 'md',
    text: 'txt',
    json: 'json',
    csv: 'csv',
    html: 'html',
  };

  try {
    // Use the Unified LLM Client for AI-powered content generation
    const llmClient = getUnifiedLLMClient();
    const isAvailable = await llmClient.healthCheck();

    if (isAvailable) {
      const result = await llmClient.generateContent('document', prompt, {
        format: format,
        style: options?.style,
        length: options?.length,
      });

      const generatedContent = result.content;
      const content = template.prefix.replace('{{date}}', new Date().toLocaleDateString()) +
                      (options?.title ? `# ${options.title}\n\n` : '') +
                      generatedContent +
                      template.suffix;

      logger.info('[Content Generate] AI-powered document generated', {
        tokensUsed: result.tokensUsed,
        format,
      });

      return {
        content,
        mimeType: mimeTypes[format] || 'text/plain',
        extension: extensions[format] || 'txt',
        tokensUsed: result.tokensUsed,
      };
    }

    // Fallback to template if LLM unavailable
    logger.warn('[Content Generate] LLM unavailable, using template fallback');
    return generateDocumentFallback(prompt, options, template, format, mimeTypes, extensions);

  } catch (error) {
    logger.error('[Content Generate] LLM error, using fallback:', error);
    return generateDocumentFallback(prompt, options, template, format, mimeTypes, extensions);
  }
}

/**
 * Fallback document generation when LLM is unavailable
 */
function generateDocumentFallback(
  prompt: string,
  options: GenerationRequest['options'],
  template: { prefix: string; suffix: string },
  format: string,
  mimeTypes: Record<string, string>,
  extensions: Record<string, string>
): { content: string; mimeType: string; extension: string; tokensUsed: number } {
  const generatedContent = `
## ${options?.title || 'Generated Document'}

${prompt}

### Content

This document was generated based on your request. The AI content generation service
is currently unavailable. Please try again later for AI-powered content.

### Details

- Request: ${prompt}
- Format: ${format}
- Style: ${options?.style || 'default'}
- Generated: ${new Date().toISOString()}
`.trim();

  const content = template.prefix.replace('{{date}}', new Date().toLocaleDateString()) +
                  generatedContent +
                  template.suffix;

  return {
    content,
    mimeType: mimeTypes[format] || 'text/plain',
    extension: extensions[format] || 'txt',
    tokensUsed: 0,
  };
}

/**
 * Generate code based on prompt using AI
 */
async function generateCode(
  prompt: string,
  options: GenerationRequest['options']
): Promise<{ content: string; mimeType: string; extension: string; tokensUsed: number }> {
  try {
    const llmClient = getUnifiedLLMClient();
    const isAvailable = await llmClient.healthCheck();

    if (isAvailable) {
      const result = await llmClient.generateCode({
        intent: prompt,
        language: 'typescript',
        framework: undefined,
        context: options?.style === 'technical' ? 'Production-ready, well-documented code' : undefined,
      });

      if (result.success) {
        logger.info('[Content Generate] AI-powered code generated', {
          tokensUsed: result.metadata.tokensUsed,
          provider: result.metadata.provider,
        });

        return {
          content: result.code,
          mimeType: 'text/typescript',
          extension: 'ts',
          tokensUsed: result.metadata.tokensUsed,
        };
      }
    }

    // Fallback
    logger.warn('[Content Generate] LLM unavailable for code, using fallback');
    return generateCodeFallback(prompt);

  } catch (error) {
    logger.error('[Content Generate] Code generation error:', error);
    return generateCodeFallback(prompt);
  }
}

/**
 * Fallback code generation when LLM is unavailable
 */
function generateCodeFallback(
  prompt: string
): { content: string; mimeType: string; extension: string; tokensUsed: number } {
  const code = `/**
 * Generated Code
 *
 * Request: ${prompt}
 * Generated: ${new Date().toISOString()}
 *
 * Note: AI code generation is currently unavailable.
 * This is a template - please implement the actual logic.
 */

// TODO: Implement based on: ${prompt}
export function generatedFunction() {
  console.log('Implementation pending - Generated by Infinity Assistant');
}

export default generatedFunction;
`;

  return {
    content: code,
    mimeType: 'text/typescript',
    extension: 'ts',
    tokensUsed: 0,
  };
}

/**
 * Generate data export using AI
 */
async function generateData(
  prompt: string,
  options: GenerationRequest['options']
): Promise<{ content: string; mimeType: string; extension: string; tokensUsed: number }> {
  const format = options?.format || 'json';

  try {
    const llmClient = getUnifiedLLMClient();
    const isAvailable = await llmClient.healthCheck();

    if (isAvailable) {
      // Ask LLM to generate structured data
      const dataPrompt = format === 'csv'
        ? `Generate CSV data for: ${prompt}. Output valid CSV with headers.`
        : `Generate JSON data for: ${prompt}. Output valid JSON only, no markdown.`;

      const result = await llmClient.generateContent('data', dataPrompt, {
        format: format,
      });

      // Try to parse and validate the output
      let content = result.content.trim();

      // Clean up any markdown code blocks
      if (content.startsWith('```')) {
        const match = content.match(/```(?:json|csv)?\n?([\s\S]*?)```/);
        if (match) content = match[1].trim();
      }

      logger.info('[Content Generate] AI-powered data generated', {
        tokensUsed: result.tokensUsed,
        format,
      });

      return {
        content,
        mimeType: format === 'csv' ? 'text/csv' : 'application/json',
        extension: format === 'csv' ? 'csv' : 'json',
        tokensUsed: result.tokensUsed,
      };
    }

    // Fallback
    return generateDataFallback(prompt, format);

  } catch (error) {
    logger.error('[Content Generate] Data generation error:', error);
    return generateDataFallback(prompt, format);
  }
}

/**
 * Fallback data generation when LLM is unavailable
 */
function generateDataFallback(
  prompt: string,
  format: string
): { content: string; mimeType: string; extension: string; tokensUsed: number } {
  if (format === 'csv') {
    const csv = `id,name,description,created_at
1,Generated Item,"${prompt.replace(/"/g, '""')}",${new Date().toISOString()}
`;
    return { content: csv, mimeType: 'text/csv', extension: 'csv', tokensUsed: 0 };
  }

  const data = {
    generated: true,
    prompt,
    timestamp: new Date().toISOString(),
    note: 'AI data generation is currently unavailable',
    data: {
      message: 'This is placeholder data based on your request',
      request: prompt,
    },
  };

  return {
    content: JSON.stringify(data, null, 2),
    mimeType: 'application/json',
    extension: 'json',
    tokensUsed: 0,
  };
}

// ============================================================================
// API HANDLER
// ============================================================================

/**
 * POST /api/content/generate
 *
 * Generate content using AI
 */
export async function POST(request: NextRequest) {
  try {
    const body: GenerationRequest = await request.json();
    const { type, prompt, conversationId, options } = body;

    if (!type || !prompt) {
      return NextResponse.json(
        { error: 'type and prompt are required' },
        { status: 400 }
      );
    }

    // Get user ID
    const userService = getUserService();
    const userId = userService.getAnonymousUserId(
      request.cookies.get('infinity_anon_user')?.value
    );

    logger.info('[Content Generate] Starting generation', {
      userId,
      type,
      promptLength: prompt.length,
    });

    // Generate content based on type
    let generated: { content: string; mimeType: string; extension: string; tokensUsed: number };

    switch (type) {
      case 'document':
      case 'report':
      case 'summary':
        generated = await generateDocument(prompt, options);
        break;
      case 'code':
        generated = await generateCode(prompt, options);
        break;
      case 'data':
        generated = await generateData(prompt, options);
        break;
      default:
        return NextResponse.json(
          { error: `Unsupported generation type: ${type}` },
          { status: 400 }
        );
    }

    // Generate filename
    const timestamp = Date.now();
    const title = options?.title || type;
    const sanitizedTitle = title.replace(/[^a-zA-Z0-9]/g, '_').slice(0, 50);
    const filename = `${sanitizedTitle}_${timestamp}.${generated.extension}`;

    // Store the generated content
    const storageService = getUserContentStorageService();
    const result = await storageService.storeGeneratedContent(
      userId,
      generated.content,
      {
        name: filename,
        mimeType: generated.mimeType,
        conversationId,
        prompt: prompt.slice(0, 500), // Store truncated prompt
        tags: ['generated', type],
      }
    );

    if (!result.success) {
      return NextResponse.json(
        { error: result.error || 'Failed to store generated content' },
        { status: 500 }
      );
    }

    logger.info('[Content Generate] Content generated and stored', {
      userId,
      contentId: result.content?.id,
      type,
      tokensUsed: generated.tokensUsed,
      aiPowered: generated.tokensUsed > 0,
    });

    // Return result with preview
    const response: GenerationResult = {
      success: true,
      content: {
        id: result.content!.id,
        name: filename,
        type: generated.mimeType,
        url: result.signedUrl || '',
      },
      preview: generated.content.slice(0, 500), // First 500 chars as preview
      tokensUsed: generated.tokensUsed,
      aiPowered: generated.tokensUsed > 0,
    };

    return NextResponse.json(response);
  } catch (error) {
    logger.error('[Content Generate] Error:', error);
    return NextResponse.json(
      { error: 'Content generation failed' },
      { status: 500 }
    );
  }
}

/**
 * GET /api/content/generate
 *
 * Get available generation types and options
 */
export async function GET() {
  return NextResponse.json({
    types: [
      {
        id: 'document',
        name: 'Document',
        description: 'Generate markdown or text documents',
        formats: ['markdown', 'text', 'html'],
        icon: 'üìÑ',
      },
      {
        id: 'report',
        name: 'Report',
        description: 'Generate structured reports',
        formats: ['markdown', 'html'],
        icon: 'üìä',
      },
      {
        id: 'summary',
        name: 'Summary',
        description: 'Generate summaries of content',
        formats: ['markdown', 'text'],
        icon: 'üìù',
      },
      {
        id: 'code',
        name: 'Code',
        description: 'Generate code snippets and files',
        formats: ['typescript', 'javascript', 'python'],
        icon: 'üíª',
      },
      {
        id: 'data',
        name: 'Data Export',
        description: 'Generate structured data exports',
        formats: ['json', 'csv'],
        icon: 'üìä',
      },
    ],
    options: {
      formats: ['markdown', 'text', 'json', 'csv', 'html'],
      styles: ['formal', 'casual', 'technical'],
      lengths: ['short', 'medium', 'long'],
    },
  });
}
